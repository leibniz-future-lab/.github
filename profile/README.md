## Leibniz AI Lab

In the International Future Lab for Artificial Intelligence ([Leibniz AI Lab](https://leibniz-ai-lab.de/)) in Hannover, excellent international researchers as well as renowned colleagues from L3S Research Center, Leibniz University, Hannover Medical School and European partner institutes have been researching new topics in artificial intelligence and developing intelligent solutions for personalised medicine.

* [SelfDistill-SER](https://github.com/leibniz-future-lab/SelfDistill-SER): **Fast yet effective speech emotion recognition with self-distillation.**
<br> We apply self-distillation  to produce a fast and effective speech emotion recognition model, by simultaneously fine-tuning wav2vec 2.0 and training its shallower versions.

* [PrototypeSound](https://github.com/leibniz-future-lab/PrototypeSound): **Prototype Learning for Interpretable Respiratory Sound Analysis.**
<br> The prototype learning framework aims to generate prototypes of audio singnals for a respiratory sound classification task (normal/crackle/wheeze/both).

* [HypercomplexECG](https://github.com/leibniz-future-lab/HypercomplexECG): **Efficient ECG-based Atrial Fibrillation Detection via Parameterised Hypercomplex Neural Networks.** 
<br> We propose lightweight convolutional neural networks  for atrial fibrillation detection based on the recently proposed parameterised hypercomplex neural networks.

* [Knowledge Acquisition](https://github.com/jwallat/knowledge-acquisition): **The Effect of Masking Strategies on Knowledge Retention by Language Model**
<br> In this work, we investigate how different training regimes affect the amount of factual knowledge that language models remember. We test for masking random words, entities, and masking multiple tokens based on point-wise mutual information.
 
* [Knowledge Probing](https://github.com/jwallat/knowledge-probing): **BERTnesia: Investigating the capture and forgetting of knowledge in BERT**
<br> We investigate how much factual knowledge is retained in the individual layers of language models. To do so, we use cloze questions (e.g., The capital of France is ___).
 
* [Probing Search](https://github.com/yolomeus/probing-search): **Probing BERT for Ranking Abilities**
<br> We investigate to what degree LMs for information retrieval encode standard abilities such as lexical or semantic similarity, named entity recognition, and others. We use that information where these models learn such abilities to train more effective models.
 
* [Temporal Blind Spots](https://github.com/jwallat/temporalblindspots): **Temporal Blind Spots in Large Language Models**
<br> We investigate to what degree LLMs are able to answer questions about historical events. Further, we explore common errors that occur when doing so.

* [clinALL](https://git.l3s.uni-hannover.de/tang/clinALL): **AI-assisted clinical framework to facilitate diagnostic and translational discovery in hematological neoplasia**
<br> clinALL is a clinical data integration, visualization and analysis framework especially designed for hematological neoplasia. Its main user interface is based on Uniform Manifold Approximation
and Projection (UMAP) analysis of the RNA sequencing data. Both clinical and genomic information provided by the users can be integrated and visualized on top of the UMAP.

* [IVP-VAE](https://github.com/jingge326/ivpvae): **IVP-VAE: Modeling EHR Time Series with Initial Value Problem Solvers**
<br> We propose a novel continuous-time model which can capture sequential patterns of EHR time series by purely solving multiple IVPs in parallel. 
By utilizing the invertibility property of IVP solvers, we achieve parameter sharing between encoder and decoder of the VAE architecture, and thus provide a more efficient generative modeling technique. 

* [Causality for Trustworthy AI](https://github.com/L3S/causality-for-trustworthy-ai): **A Review of the Role of Causality in Developing Trustworthy AI Systems â€“ Datasets and Packages**
<br> This repository is a curated list of datasets used for recent Causal Machine Learning (ML) publications we covered in our survey. It also includes an overview of useful causal and non-causal tools and packages to assess different characteristics of ML models (e.g., robustness or fairness) and for use in healthcare.

* [GeneMask](https://github.com/roysoumya/GeneMask): **GeneMask: Fast Pretraining of Gene Sequences to Enable Few-Shot Learning**
<br> We propose a novel masking algorithm for Masked Language Modeling training of gene sequences. Here, we provide the resources required for (a) Computing for all 6-mers based on the Human Reference Genome, (b) PMI-best - pretraining and finetuning, (c) Datasets of Prom-core, Prom-300, and Cohn-enh used for the different few-shot settings, (d) de-novo motif discovery using the rGADEM R package.

* [Knowledge Aware Med Classification](https://github.com/roysoumya/knowledge-aware-med-classification): **Knowledge-Aware Neural Networks for Medical Forum Question Classification**
<br> We develop a novel medical knowledge-aware BERT-based model (MedBERT) that explicitly gives more weightage to medical concept-bearing words, and utilize domain-specific side information obtained from a popular medical knowledge base. 
We also contribute a multi-label, multi-class dataset where we annotate the existing CADEC dataset into five information need categories for the "Medical Forum Question Classification" task.

* [MPSS Clinical Trial Search](https://github.com/roysoumya/MPSS-clinical-trial-search): **Interpretable Clinical Trial Retrieval System using Pubmed Citation Network**
<br> We propose a graph-based model that explores both clinical trials and the Pubmed databases to alleviate the shortage of relevant clinical trials for a query. We make all the codes and data available. Specifically, we contribute a disease-independent evaluation dataset for clinical trial search systems that may encourage more research into this critical domain.

* [Graph Learning Based AMDP](https://github.com/xy9485/GraphLearningBasedAMDP): **Graph learning-based generation of abstractions for reinforcement learning**
<br> This work targets hierarchical reinforcement learning by incorporating a higher-level Markov decision process that helps speed up convergence of reinforcement learning.

* [Deep Value Q-learning RL](https://github.com/xy9485/DVQN_RL): **Regulating Action Value Estimation in Deep Reinforcement Learning**
<br> We propose a novel method called Deep Value Q-learning, which regulates the estimation of action values, tackles the overestimation issue of deep Q-learning and improves sample efficiency of reinforcement learning. 
